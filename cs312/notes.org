#+title: CS312 Notes
# #+setupfile: ../jake.setup
#+options: \n:t

* Theory Of Computation Introduction
The 3 componenets of problem solving
1. Unknowns
2. Data
3. Conditions

To solve a problem we need to find a way of determining the unknowns from given data such that conditions of the problem are satisfied.

The traditional areas of the theory of computation (TOC)
- Automata
  - Provide problem solving devices
- Computability
  - Provide framework that can characterize devices by their computing power
- Complexity
  - Provide framework to classify problems acording to time/space complexity of the toold used to solve them

** Automata (Automaton)
- Abstration of computing devices
- How much memory can be used?
- What operations can be performed?

** Computability
- Study different computing models and identify the most powerful ones
- Range of problems
- Problems can be undecidable or uncomputatble
  - The halting problem

** Complexity
- Computing problems range from easy to hard; sorting is easier than scheduling
- Question
  - What makes some problems computationally hard or others easy?

** Problem Abstration
Data
- Abstracted as a word in a given alphabet
Conditions
- Abstracted as a set of words called a language
Unknowns
- A boolean variable: true if a word is in the language or false other wise

*** Abstration of Data
- \Sigma: alphabet, a finite, nonempty set of symbols
- \Sigma^{*}: all words of a finite length built up using \Sigma
- Rules: (1) the empty word (\epsilon) is in \Sigma^{*}; (2) if w \in \Sigma^{*} and a \in \Sigma, then aw \in \Sigma^{*}, and (3) nothing else is in \Sigma^{*}

Example: If \Sigma = {0,1}, then \Sigma^{*} = {\epsilon,0,1,00,01,10,11,000,001,010,011,...}.

**** Valid C
#+begin_src C
int my_func() { return 1; };

int main() {
    int var = my_func(1,2,3,4,5,6,7);
    for (;;) {}
    // You cannot just simply change the syntax of a for loop
    for(;) {}
}
#+end_src

#+RESULTS:
**** Invalid C++
#+begin_src C++
int my_func() { return 1; };

int main() {
    int var = my_func(1,2,3,4,5,6,7);
    for (;;) {}
    // You cannot just simply change the syntax of a for loop
    for(;) {}
}
#+end_src

#+RESULTS:

* Finite Automata
** Formal Language
- Some set of strings over a give alphabet
- How do you specify a language?
- How do you recognize strings in a language?
- How do you translate the language?
** Abstraction of Problems
1. Data - word in a given alphabet
   - \Sigma alphabet, a finite non-empty set of symbols
   - \Sigma^* all words of finite length built-up using \Sigma
2. Conditions - Set of words called a language
   - Any subset L \subseteq \Sigma^* is a formal language
3. Unknown - a boolean variable that is true, if word is in language; false, otherwise.
   - Given w \in \Sigma^* and L \subseteq \Sigma^*, is w \in L?
** Formal Definition
- Simplest computational model also referred to as a finite-state machine or finite automaton (FA)
- Representations: graphical, tabular, and mathmatical
- A finite automaton is a 5-tuple (Q,\Sigma,\delta,q_{0},F), where Q is a finite set of states, \Sigma is a finite set of symbols (alphabet), the transition function \delta maps Q X \Sigma to Q, q_0 \in Q is the start (initial) state, and F $\subseteq{}$ Q is the set of accept (final) states
- Used to design embedded systems, or compilers
*** Example
If the machine is in a start state, where the initial state is an accept state, that means that our FA can accept an empty string \epsilon
** DFA
Deterministic Finite Automata
** Applications
- Parsers for compilers
- Pattern recognition
- Speech processing and OCR
- Financial planning and market prediction
** FA Computation
- Automaton M_{1} receives input symbols one-by-one (left to right)
- After reading each symbol, M_{1} moves from one state to another along the transition that has that symbol as its label
- When M_{1} reads the last symbol of the input, it produces the output: accept if M_{1} is in an accept state, or reject if M_{1} is not in an accept state
** Language Recognition
- If L is the set of all strings that an FA M accepts, we say that L is the language of the machine M and write L(M) = L
- An automaton may accept several strings, but it always recognizes only one language
- If a machine accepts no strings, it still recognizes one language, namely the empty language 0
The machines are recognizing words in the language
Any given automaton only recognizes specifically one language
** Formal Definition of Acceptance
- LEt M = (Q,\Sigma,\delta,q_{0},F) be an FA and w = a_{1}a_{2}...a_{n} be a string over \Sigma. We say M accepts w if a sequence of states r_{0}r_{1}...r_{n} exist in Q such that
  - r_{0} = q_{0} (where machine starts)
  - \delta{}(r_{i},a_{i+1}) = r_{i+1}, i=0,1,...,n-1,(transitions based on \delta)
  - r_{n} \in F (input accepted)
** Regular Languages
- We say that FA recognizes the language L if L = {w | M accepts w}
- A language is called a *regular* language, if there exists an FA that recognizes it
- Q: how do you design/build an FA
** FA Design Approach
1. Identify finite pieces of information you need, i.e., the states (possibilities)
2. Identify the condition (or alphabet) to change from one state to another
3. Idenitfy the starting and final/accept states
4. Add missing transitions
** Example
Let M_{1} = (Q,\Sigma,\delta,q_{1},F), Q = {q_{1},q_{2},q_{3}}, \Sigma = {0,1}, and F = {q_{2}}. Let's define a transition functoin \delta for M_{1} and then draw the resulting (graph-based) *state transition diagram* for M_{1}

DFA, this table is Q X \Sigma \rightarrow{} Q
q_{1} is the start state
q_{2} is the accept

|       | 0     | 1     |
|-------+-------+-------|
| q_{1} | q_{1} | q_{2} |
| q_{2} | q_{3} | q_{2} |
| q_{3} | q_{2} | q_{2} |

#+begin_export latex
\tikzset{
        ->, % makes the edges directed
        node distance=3cm, % specifies the minimum distance between two nodes. Change if necessary.
        every state/.style={thick, fill=gray!10}, % sets the properties for each â€™stateâ€™ node
        initial text=$ $, % sets the text that appears on the start arrow
}
#+end_export


#+begin_export latex
\begin{tikzpicture}
        \node[state, initial] (q1) {$q_1$};
        \node[state, accepting, right of=q1] (q2) {$q_2$};
        \node[state, right of=q2] (q3) {$q_3$};
        \draw (q1) edge[loop above] node{0} (q1)
        (q1) edge[above] node{1} (q2)
        (q2) edge[loop above] node{1} (q2)
        (q2) edge[bend left, above] node{0} (q3)
        (q3) edge[bend left, below] node{0, 1} (q2);
\end{tikzpicture}
#+end_export

*** Notes on Example
L(M_{1}) = ?
L(M_{1}) = A
A = {w | w contains at least one 1 AND an event number of 0's following the last 1}

** Example 2
\delta{}  Q X \Sigma \rightarrow{} Q

|       | 0     | 1      |
|-------+-------+--------|
| q_{1} | q_{1} | q_{2}  |
| q_{2} | q_{1} | q_{2}  |

#+begin_export latex
\begin{tikzpicture}
        \node[state, initial] (q1) {$q_1$};
        \node[state, accepting, right of=q1] (q2) {$q_2$};
        \draw (q1) edge[loop above] node{0} (q1)
        (q1) edge[bend left, above] node{1} (q2)
        (q2) edge[loop above] node{1} (q2)
        (q2) edge[bend left, below] node{0} (q1)
\end{tikzpicture}
#+end_export

L(M_{2}) = B = { w | w ends in a 1 }

*** Expanstion on Above M_{3}

#+begin_export latex
\begin{tikzpicture}
        \node[state, initial, accepting] (q1) {$q_1$};
        \node[state, right of=q1] (q2) {$q_2$};
        \draw (q1) edge[loop above] node{0} (q1)
        (q1) edge[bend left, above] node{1} (q2)
        (q2) edge[loop above] node{1} (q2)
        (q2) edge[bend left, below] node{0} (q1)
\end{tikzpicture}
#+end_export

Language of M_{3} = C = { w | w ends in a 0 OR w is empty }

*** What does this give us?
If we flip the accept and initial state, we generate the complement of the machine (flip the meaning)

** Last DFA Example
Q={s,q_{1},q_{2},r_{1},r_{2}}
\Sigma={a,b}
F = {q_{1},r_{1}}

\Delta chart
|       | a     | b     |
|-------+-------+-------|
| s     | q_{1} | r_{1} |
| q_{1} | q_{1} | q_{2} |
| q_{2} | q_{1} | q_{2} |
| r_{1} | r_{2} | r_{1} |
| r_{2} | r_{2} | r_{1} |

#+begin_export latex
\begin{tikzpicture}
        \node[state, initial] (s) {$s$};
        \node[state, accepting, right of=s] (q1) {$q_1$};
        \node[state, accepting, left of=s] (r1) {$r_1$};
        \node[state, below of =q1] (q2) {$q_2$};
        \node[state, below of =r1] (r2) {$r_2$};
        (s) edge[] node{a} (q1)
        (s) edge[] node{b} (r1)
        (q1) edge[loop above] node{a} (q1)
\end{tikzpicture}
#+end_export

{ w | starts with 'a' AND ends with 'a' }

* Regular Languages
Let A and B be languages
Union: A \union B = { x | x \in A \vee x \in B }
Concatenation: A \circ B = { xy | x \in A \wedge y \in B }
Star: A^{*} = { x_{1}x_{2}...x_{k} | k >= 0 \wedge x_{i} \in A, 0 <= i <= k }

*** Is \epsilon always a member of A^{*} regarless of the language A?
Yes
*** What is another name for the language of A \circ A^{*}?
A^{+}

*** Closures of Regular Languages
Theorem: Class of regular languages is closed under intersection. (Proof: Use cross-product construction of states)
Theorem: Class of regular languages is closed under complementation (Proof: swap accept/non-accept states and show FA recognizes the complement)
** Nondeterminism
NFA or nondeterministic finite automata
- Every stop of a FA computation follows in a unique way from the proceeding step; a deterministic computation
- Nondeterministic computation - choices exist for the next state; a nondeterministic FA (NFA)
- Ways to introduct nondeterminism
  - more choices for next state (zero, one, many)
  - State may change to another state without reading any symbol

*** Formal Definition
a 5-tuple (Q, \Sigma, \delta, q_{0}, F), where Q is a finite set of states, \Sigma is a finite set of symbols (alphabet), the transition function \delta maps Q x \Sigma \union {\epsilon} to \mathbb{P}(\mathbb{Q}), q_{0} \in Q is the start (initial) state, and F $\subseteq{}$ Q is the set of accept (final) states.

Notice that the range of the transition function \delta for an NFA is the power set of Q \mathbb{P}(\mathbb{Q})

*** Formal Definition of Acceptance (NFA)
Let N  k (Q, \Sigma, \delta, q_{0}, F) be an NFA and w = y_{1}y_{2}...y_{n} be a string over $\Sigma_{\epsilon}=\Sigma{}\union{}{\epsilon}$. We say N accepts w if a sequence of states r_{0},r_{1},...,r_{m} exist in Q such that
1. r_{0} = q_{0}
2. \delta(r_{i},y_{i+1}) = r_{i+1} for i = 0,1,...,m-1
3. r_{m}\in{}F

*** NFA Motivation
- For some problems they are much easier to construct than a DFA
- NFA may actually be smaller than a DFA that performs the same task; but NFA computation is usually more expensive
- Every NFA can be converted into an equivalent DFA (in theory, every NFA has an equivalent DFA t orecognize the same language)
- NFAs can be used to show that regular languages are closed under union, concatenation, and star operations

Epsilon transitions happen without reading anything, allowing you to go either direction

*** DFA/NFA Equivalence
Let N = (Q, \Sigma, \delta, q_{0}, F) be the NFA that recognizes the language A and construct the DFA M that also recognizes A. Define M = (Q', \Sigma, \delta{}', q_{0}', F').


E(R) = R \Union {q \in Q | \quantifier{}r_{1} \in R,r_{2},...,r_{k} \in{} Q, r_{i+1} \in \delta(r_{i},\epsilon), r_{k} = q}

* Nonregular Languages
R is a regular expression if
1. a for some a \in \Sigma
2. \epsilon (language contains only the empty string)
3. 0 (language has no strings)
4. (R_{1} \union R_{2}), where R_{1}, R_{2} are regular expressions
5. (R_{1} \circ R_{2}), where R_{1}, R_{2} are regular expressions
6. R_{1}^{*}, where R_{1} is a regular expression

** Language Example
Is B = {0^{n}1^{n}|n \geq 0} a regular language?
- No because one single machine cannot possible match the infinte states

*** Warning
Just because a language might seem to require unbounded (infinite) memory t orecognize it - it could still be regular

Suppose you have the following two languages: C = {w | w has an equal number of 0s and 1s} and D = {w | w has an equal number of 01 and 10 substrings}

2nd is regular?

** Example
Language D = {w|w has an equal number of 01 and 10 substrings}

We can generally create a regular language if the constraints are ordering
Generally non-regular if we have to do some sort of counting without ordering

* Pumping Lemma
- All strings in a language can be pumped if they are at least as long as a certain value called the pumping length
- Another interpretation: every string contains a section that can be repeated any number of itmes with the resulting string remaining in the language

** Example
sqrt(sqrt(sqrt(...sqrt(x)...)))

** Lemma
If A is a regular language, then there exists a number p (the pumping length) where, if s is any string in A of length of at least p, then s may be divided into three pices, s = xyz subject too

If you take any string out of the language, at least length p, then I can take that string, cut it into pieces, 3 pieces, prefix x, suffix z,

1. \forall i \geq 0, xy^{i}z \in A
   - p is an integer
   - You can also remove all y's, 0 y's
2. |y| > 0
   - The actual substring must have some chars
   - x and z can both be empty strings
3. |xy| \leq p
   - the length of x+y cannot be bigger than p

** Pumping Lemma Proof Construction
- Let M = (Q,\Sigma,\delta,q_{1},F) be a DFA that recognizes the language A. Assign a pumping length p to the number of states of M.
  - P (pumping length) is the number of states in M, which is finite
  - If you have finite number of states (p), and it is way bigger than p, then we will have to loop
- Show that any string s \in A, |s| \geq p may be broken into xyz satisfying the three PL conditions
  -
- If there are no strings in A of length at least p, then the PL is true because all three conditions hold for all strings of length at least p (if there are NO such strings)

** Proof
Recognizes A and let p be the size of Q, let s = s_{1}s_{2}...s_{n} be a string over \Sigma with n \geq p and r = r_{1}r_{2}...r_{n+1} be the sequence of states encountered while processing

*** Example
We know that n+1 \geq p+1, why?
- because n \geq p

The among the first p+1 elements in the sequence r..., there must be a repeating state, say r_{j},r_{k} what principle is this based on?
- Pigeon hole principle

Let r_{k} be the recurring state among the first p+1 states in the sequence starting with r_{1}, so k \leq p+1. Let x = s_{1}s_{2}...s_{j-1}, y = s_{j}s_{j+1}...s_{k-1}, and z = s_{k}s_{k+1}...s_{n}

So X takes M from r_{1} to r_{j}, Y takes M from r_{j} to r_{j} and Z takes M from r_{j} to r_{n+1}; recall that r_{j} == r_{k} and that r_{n+1} is an accept state
Therefore:
- M must accept xy^{i}z, for i \geq 0 (*Condition 1*)
- Since j \neq k then |y| \gt 0 (*Condition 2*)
- Since k \le p + 1 then |xy| \leq p (*Condition 3*)

** Technique
- Assume the language is regular, and assume a contradiction
- PL guarantees existence of a pumping length p such that all strings of length p or greater (in A) can be pumped
- Find s \in A, |s| \geq p that cannot be pumped; consider all the ways of dividing s int ox,y,z and show that for each division, at least one of the PL conditions fail to hold
- pumping length = number of states in a minimalist machine

*** Example
B = {0^{n}1^{n} | n \geq 0} is not regular

Assume B is regular and let p be the pumping length for B. Choose s = 0^{p}1^{p} \in B so that clearly s \ge p. By the PL, we can partition s = xyz such that for all i \geq 0, xy^{i}z \in B. Let's consider three possible cases for the contents of substring y

Think about what the string is, in our case s = 00...011...1, where our length is now 2p, p 0's followed by p 1's.

|   x |    y |   z |
| 000 | 0011 | 111 |

**** Options
1. Y consists of only 0's
   - x   | y  | z
   - 0000|...0|111.11
   - Then S' = xyyz
   - Then S' has more 0's than 1's, therefore it is no longer in the language
   - Hence, xyyz \notin B, a violation of condition 1 of the PL
   - Y consists only of 0's. Then S' = xyyz has more 0's than 1's since |y| > 0 by condition 2. Hence, xyyz \notin{} B. This is a violation of condition 1 of the PL.
2. Y consists of only 0's
   - Y consists only of 1's. Then S' = xyyz has more 1's than 0's since |y| > 0 by condition 2. Hence, xyyz \notin{} B. This is a violation of condition 1 of the PL.
3. Y consists of 0's and 1's
   - Y consists of 0's and 1's. Then s' = xyyz may have the same number of 0's and 1's, but they are out of order (i.e some 1's occur before 0's), and so s' = xyyz \notin{} B. This is a violation of condition 1 of the PL.

** How might the proof above be simplified using condition 3 of the PL to constrain the contents of the substring y?
According to condition 3, we must have |xy| <= p.

We picked s = 0000000|1111111, both of length p
xy is already p length, therefore the language only contains 0's.
y could only contain 0's and we have contradiction in case 1 for all y

*** Example
i = 2
New string is xz


** Conditions
- If a language is regular, one should be able to take any string out of that language, partition it into 3 parts XYZ, with the Y componenet having something in it, then you can pump that string
- \forall{} i \geq 0, XY^{i}Z has to be in the language, if i = 0 we are pumping down, if i \gt 1 we are pumping up
- We only have to find one i that breaks the conditions, because the condition says \forall{} i's

- if i = 1, then we are not pumping, that is just the same string
- When i \geq 2 then we are pumping up
- When i \eq 0 then we are pumping down

** Example Again
Use the PL to prove that the language E = {0^{i}1^{j} | i > j} is not regular.

Assume E is regular and let p be the pumping length for E. Choose s = 0^{p+1}1^{p} \in E so that clearly s > p. By the PL, we can partition s = xyz such that for all i >= 0, xy^{i}z \in E. By condition 3 of the pumping lemma, we must have |xy| \leq p. Therefore, y must contain only 0's. Is it possible for s' = xyyz to be in the language? Adding an additional copy of y increases the number of 0's which does not violate the constraints of the language. But setting i = 0 does violate the condition since we would now have 0^p and 1^p, or more generally i <= j. Subsequently s' would \notin E, given this contradiction of conditoin 1 of the PL, we can conclude E is not regular.

Start with condition 3 of the PL to determine the contents of substring y and see if you can get a violation of Condition 1 of the PL for any choice of y.

** Another example
*** Language 1
L_{1} = {a^{i}ba^{j} | 0 \leq i < j}
- ba
- Assume L_{1} is regular with pumping length p
- Choose s = a^{p}ba^{p+1}
- State cond 1, s = xyz \forall i \geq 0 xy'z \in L_{1}
- Use condition 3 (|xy| \leq p), and condition 2 (|y| > 0)
- y contains only a's
- Pumping up violates the constraint i < j, because xyyz would result in i is now greater than j, which means j is no longer strictly greater than i
- Therefore s' \notin L_{1}, a's before b are greater than or equal to those after b

* Context Free Languages
We have shown that L = {0^{n}1^{n} | n \geq 0} cannot be specified by a FA or regular expression; Context-Free Grammars (or CFGs) provide a more powerful way to specify languages. A CFG is a 4-tuple (V, \Sigma, R, S), where
- V is a finite set of symbols (variable or nonterminals)
- \Sigma is a finite set of symbols disjoint from V (terminals)
- R is a finite set of specification rules of the form /lhs/ \rightarrow{} /rhs/, /lhs/ \in V, /rhs/ \in (V \union \Sigma), and S \in V is the start variable

** Example
CFG G_{1} has the following specification rules
\[
A \rightarrow{} 0A1
\]
\[
A \rightarrow{} B
\]
\[
B \rightarrow{} \#
\]

The start variable for G_{1} is A.
What are the nonterminals?
- A, B
What are the terminals?
- 0, 1, #

** Language Specification
1. Write down start variable; /lhs/ of first spec rule
2. Find variable that is written down and a rule whose /lhs/ is that variable; replace the written down variable with the /rhs/ of that rule
3. Repeat Step 2 until no variables remain in string

*** Example
Use the CFG G_{1} (above) to derive the string 000#111. Show derivation and corresponding parse tree

** Direct Derivation
If u,v,w \in (V \union \Sigma)^{*}, i.e., are strings of variables and terminals, and A \rightarrow{} w \in R is a grammar rule, then we say that uAv yields uwv or uAv \Rightarrow{} uwv. Alternatively, uwv is directly derived from uAv using the rule A \rightarrow w.

** Derivation
\[
S \rightarrow aSb
\]
\[
S \rightarrow SS
\]
\[
S \rightarrow \epsilon
\]

** Applications
- Compiler design and implementation
- Programming language specificatoin
- Scanner, parsers, and code generators

** Design Techniques
1. CFG Design Technique
   - Many CFGs are unions of simpler CFGs
   - Combination involves putting all the rules together and adding the new rules
   - s \rightarrow s_{1}|s_{2}|...|s_{k}
     - where the variables s_{i}, 1 \leq i \leq k, are the start variables of the invidivual grammars and the s is a new variable

#+begin_src C
int a = 5;

return a + a a;
#+end_src

#+RESULTS:
*** Design a Language Example
CFG G = ({S,B}, {a,b}, {S \rightarrow{} aSB|B|\epsilon{}, B \rightarrow{} bB|b} S)

{a^{n}b^{m} | n <= m}

** Ambiguous Grammar
Consider the CFG G_{5} that has the rules E \rightarrow{} E + E | E * E | (E) | a.

For this out by parsing left to right

*** Derivation Order
It is possible for 2 derivations to produce hte same derivation becuase htey differ in the order

Leftmost derivation, replace the leftmost nonterminal first
Rightmost Derivation, replace the rightmost nonterminal at each step

*** Example
\Sigma{} = {a,b,c}
A = {a^{i}b^{j}c^{k} | i = j \vee{} j = k \hat{} (i,j,k \geq 0)}

Rules
- S \rightarrow{} E_{ab}C | AE_{bc}
- E_{ab} \rightarrow{} aE_{ab}b | \epsilon{}
- E_{bc} \rightarrow{} bE_{bc}C | \epsilon{}
- C \rightarrow{} Cc | \epsilon{}
- A \rightarrow{} aA|\epsilon{}

Based on the rules defined above:
S \rightarrow{} E_{ab}C \rightarrow{} C \rightarrow{} \epsilon{}
S \rightarrow{} AE_{bc} \rightarrow{} A \rightarrow{} \epsilon{}

How can we eliminate the ambiguity?

Remove the epsilons from the RHS
- C \rightarrow{} Cc | *c*
- A \rightarrow{} aA| *a*

Leave the intial 2 rules alone, *but we removed the empty string*
- S \rightarrow{} E_{ab}C | AE_{bc} | *\epsilon{}* | *E_{ab}* | *E_{bc}*

** Real World Example
#+begin_src
<s> ::= <v>=<e>
     | <s>;<s>
     | if <b> then <s>
     | if <b> then <s> else <s>
<v> ::= x|y|z
<e> ::= <v>|0|1|2|3|4
<b> ::= <e> === <e>

x=1; y=2; if x === y then y = 3
#+end_src

*** Parse Tree 1
if x === 1 then
        if y === z then
                z = 2
                else z = 3
        else z = 4

** Chomsky Normal Form
The CNF is a simplification procedure for CFGs. jthe format for rules in CNF has one of two forms
- A \rightarrow{} BC (or A \rightarrow{} AC)
  - Variable producing 2 variables on the right
- A \rightarrow{} a
  - The rule causes a termination
  - where a is a terminal and A,B,C are nonterminals and B,C may not be the start variable.
  - The rule S \rightarrow{} \epsilon{} for the start variable S is not excluded

*** Not in CNF
- A \rightarrow{} aa
  - Produce 2 terminals
- A \rightarrow{} Aa
  - Produce a nonterminal and a terminal
- A \rightarrow{} BCD
  - 3 variables

** Theorem Any CFL can be generated by a CFG in CNF
1. Add a new start symbol S_{0} and rule S_{0} \rightarrow{} S, where S was the original start var (do not want S in the /rhs/ of any rule)
2. Eliminate all \epsilon{}-rules
   - Repeat until all \epsilon{}-rules are removed
   - Eliminate the \epsilon{}-rule A \rightarrow{} \epsilon{}, where A is not the start var
   - For each occurence of A on th /rhs/ of a rule, add a new rule with that occurrence of A delted
   - Replace the rule B \rightarrow{} A (if present) by B \rightarrow{} A | \epsilon{} unless the rule B \rightarrow{} has not been previously eliminated
     - To delete A \rightarrow{} \epsilon{}, replace B \rightarrow{} uAv by B \rightarow{} uAv | uv; replace B \rightarrow{} uAvAw by B \rightarrow{} uAvAw | uvAw | uAvw | uvw.
3. Remove all unit rules (inherit /rhs/)
   - Repeat until all unit rules are removed
   - Remove a unit rule A \rightarrow{} B
4. Convert all remaining rules (cleanup)
   - Replace a rule A \rightarrow{} u_{1}u_{2}...u_{k},k \geq{} 3, where each u_{i}, 1 \leq{} i \leq{} k, is a veriable or a terminal, by A \rightarrow{} u_{1}A_{1}, A_{1} \rightarrow{} u_{2}A_{2},...,A_{k-2} \rightarrow{} u_{k-1}u_{k}, where A_{1},A_{2},...A_{k-2} are new variables
   - If k \geq{} 2, replace any terminal u_{k} with a new varible U_{i} and add the rule U_{i} \rightarrow{} u_{k}

*** Example
S \rightarrow{} ASA | aB
A \rightarrow{} B | S
B \rightarrow{} b | \epsilon{}

1. New start variable
   - S_{0} \rightarrow{} S
   - S \rightarrow{} ASA | aB
   - A \rightarrow{} B | S
   - B \rightarrow{} b | \epsilon{}
2. Remove \epsilon{} rules (remove B \rightarrow{} \epsilon{})
   - S_{0} \rightarrow{} S
   - S \rightarrow{} ASA | aB | *a*
   - A \rightarrow{} B | S | *\epsilon{}*
   - B \rightarrow{} b +| \epsilon{}+
3. Remove \epsilon{} rules pt2 (remove A \rightarrow{} \epsilon{})
   - S_{0} \rightarrow{} S
   - S \rightarrow{} ASA | aB | a | *SA | AS | S*
   - A \rightarrow{} B | S +| \epsilon{}+
   - B \rightarrow{} b
4. Remove Unit rules (All single transfers (e.g A \rightarrow{} B)) Removing S \rightarrow{} S
   - S_{0} \rightarrow{} S
   - S \rightarrow{} ASA | aB | a | SA | AS +| S+
   - A \rightarrow{} B | S
   - B \rightarrow{} b
5. Remove Unit rules (removing S_{0} \rightarrow{} S)
   - +S_{0} \rightarrow{} S+
   - *S_{0} \rightarrow{} ASA | aB | a | SA | AS*
   - S \rightarrow{} ASA | aB | a | SA | AS
   - A \rightarrow{} B | S
   - B \rightarrow{} b
6. Remove Unit rules (removing A \rightarrow{} B)
   - S_{0} \rightarrow{} ASA | aB | a | SA | AS
   - S \rightarrow{} ASA | aB | a | SA | AS
   - A \rightarrow{} +B |+ S
   - *A \rightarrow{} b*
   - B \rightarrow{} b
7. Remove Unit rules (removing A \rightarrow{} S)
   - S_{0} \rightarrow{} ASA | aB | a | SA | AS
   - S \rightarrow{} ASA | aB | a | SA | AS
   - +A \rightarrow{} S+
   - *A \rightarrow{} ASA | aB | a | SA | AS*
   - A \rightarrow{} b
   - B \rightarrow{} b
8. Stage 4 Cleanup
   - S_{0} \rightarrow{} *ASA* | *aB* | a | SA | AS
   - S \rightarrow{} *ASA* | *aB* | a | SA | AS
   - A \rightarrow{} *ASA* | *aB* | a | SA | AS
   - A \rightarrow{} b
   - B \rightarrow{} b

   - Final
     - S_{0} \rightarrow{} AA_{1}| UB | a | SA | AS
     - S \rightarrow{} AA_{1}| UB | a | SA | AS
     - A \rightarrow{} b | AA_{1}| UB | a | SA | AS
     - B \rightarrow{} b

   - Additions
     - A_{1} \rightarrow{} SA
     - U \rightarrow{} a

* Exam 1 Prep
1. Be able to produce an equivalent DFA (via state diagram) from a given NFA (along with reduction of states in the DFA)
2. Given a regex, be able to describe the language generated and/or indicated if a particular string would be in the language
3. Given a 5-tuple definition of a finite automata, be able to draw the corresponding state diagram
4. Be able to produce a DFA for a language using the cross-product of 2 simpler DFAs
5. Be able to produce a DFA for a language using the complement of a simpler DFA
6. Given a CFG be able to product a derivation or parse tree for a string in the language described by the CFG and also be able to determine if a given strin would be in the language described by the CFG
7. Be able to use the PL to show that a given language is not regular
8. Product a CFG to generate workds for a gvien context-free language

* Pushdown Automata
A pushdown automata (or PDA) is similar to an NFA but it has a stack. The stack provides additional memory beyond finite memory available in control; it allows the PDA to recognize some nonregular languages.

2 options to prove htat a language is context-free
- Construct a CFG that generates it
- Construct a PDA that recognizes it

Some CFLs are more easily descibed in terms of their generators, whereas others are more easily described in terms of their recognizers. Let's draw a schematic representation of the difference between an NFA and a PDA.

** Terminology
- Writing a symbol on the stack is called pushing the symbol
- Removing a symbol from the stack is called popping the symbol
- All access to the stack may be done only at the top (LIFO storage device)

The primary benefit of that stack is that it can hold an *unlimited* amount of data; a PDA can recognize {0^{n}1^{n} | n \geq 0} because it can use the stack to remember that number of 0s it has seen (read)

** Informal Algorithm for {0^{n}1^{n} | n \geq 0}
1. Read symbols from the input, push a 0 for each 0 you see
2. As soon as a 1 is read, pop a 0 off the stack (for each 1 read).
3. If input finishes when the stack become empty, accept; if stack becomes empty while there is still input or input finishes while the stack is not empty, reject.

A PDA may be nondeterminisitic. Languages as the one above do not require nondeterminism. However, the language {ww^{R} | w \in {0,1}^{*}} would require nondeterminism. Why?

** Formalization
- A PDA may different alphabets for input (\Sigma{}) and stack (\Gamma{})
- Nondeterminism allows for the PDA to make transitions on empty input. Define \Sigma{}_{\epsilon} = \Sigma{} \union {\epsilon} and \Gamma{}_{\epsilon} = \Gamma{} \union{} {\epsilon}
- The domain of the PDA transition function is Q x \Sigma{}_{\epsilon{}} x \Gamma{}_{\epsilon{}}, where Q is the set of states
- The range of the PDA transition funciton is P(Q x \Gamma{}_{\epsilon{}}).
\[
\delta{}: Q x \Sigma{}_{\epsilon{}} x \Gamma{}_{\epsilon} \rightarrow{} P(Q x \Gamma{}_{\epsilon})
\]

** Formal Def
A PDA is a 6-tuple (Q, \Sigma{}, \Gamma{}, \delta, q_{0}, F), where Q, \Sigma{}, \Gamma{} are finite sets of states

** PDA Computation
A PDA M = (Q,\Sigma{},\Gamma{},\delta{},q_{0},F) computes as follows...
M inputs w = w_{1}w_{2}...w_{m}, where each w_{i} \in \Sigma{}_{\epsilon}
1. r_{0} = q_{0},s_{0} = \epsilon{}; begin with state state and empty stack
2. (r_{i+1},b) \in \delta(r_{i},w_{i+1},a), i = 0,1,...m-1, where s_{i} = at and s_{i+1} = bt for some a,b \in \Gamma{} and t \in{} \Gamma{}^{*}
3. r_{m} \in F; accept state encountered at end of input

** Stack Notation
a,b \rightarrow{} or simply abc
- a = input
- b = what are you popping
- c = push onto stack
A is read from the input, b is poppped from the stack, and c is pushed onto the stack
\epsilon{}-cases
- If a = \epsilon{}, machine can transition without reading any input
- if b = \epsilon{}, machine can transition without popping any symbol from the stack
- if c = \epsilon{}, machine can transition without writing any symbol onto the stack

read pop push

** Empty Stack
The PDA does not consider the testing of an empty stack. We can achieve this by initially placing a special char (say $) on the stack. When the PDA encounters that char ($) again (on the stack), it knows the stack is effectively empty.

Both CFGs and PDAs specify context-free languages; we can always convert a CFG into a PDA that recognizes the language of the CFG

** Theorem
CFG - specifies a program language
PDA - specifies/implements the compiler

A language is context-free \iff{} some PDA recognizes it

** Difficulties
How do we decide which substitutions to make for a derivation? (PDA P nondeterminism can help)
- At each step of the derivation one of the rules for a particular variable is selected non-deterministically
- P has to start by writing the start variable on the stack and then continue working the string w
- If while consuming the string w, P arrives at a string of terminals that equals w

** Informal Description
Place marker symbol $ and tart varaible on the stack
Repeat:
- If TOS is a variable symbol A, non-deterministically select a rule r such that lhs(r) = A and substitute A by the string rhs(s)
- If TOS is a terminal symbol, a, read the next input symbol and compare it with a; if they match, pop the stack; if they do not match, reject this branch of nondeterminism
- If TOS is a $ and all the text has been read, accept; otherwise reject

** Generic State Diagram
1. TOS = variable: set \delta(q_{loop}, \epsilon{}, A) = {(q_{loop}, w) | A \rightarrow{} w \in R}, where R is the set of CFG rules
2. TOS = terminal: set \delta(q_{loop}, a, a}) = {(q_{loop}, \epsilon{}})
3. TOS = $: \delta(q_{loop}, \epsilon, $) = {(q_{accept}, \epsilon)}

* Pumping Lemmas
Pumping Lemma for CFLs
- If A is a CFL, then there exists a number p (the pumping length) where, if s is any string in A of length of at least p, then s may be divided into 5 pieces, s = uvxyz, satisfying the folloing conditions
  1. \forall{}i \geq{} 0, uv^{i}xy^{i}z \in A
  2. |vy| > 0 (i.e., either v or y is not \epsilon{})
  3. |vxy| \leq{} p (i.e., the interior cannot be larger than p).

** Schmatic Proof
Proof, Let A be a CFL and G be the CFG that generates A. We have to show that any sufficiently long s \in A can be pumped and remain in A.
- Because s \in a, it is derivable from G and say has a derivation tree D_{s}
- The tree D_{s} must be very tall (for a long s)
- So d_{s} contains some relatively long path from the start variable (at root) to a terminal at a leaf
- On such a long path, some variable X must be repeated due to the pigeonhole principle
- The repetition of X allows for the replacement of a subtree under the second occurrence of X to be replaced by the subtree under the first occurrence of X

So we may cut s into five pieces and repeat the 2nd and 4th partitions to obtain uv^{i}xy^{i}z \in A, for any i \geq 0

** Example
Use the PL for CFLs to prove that the language B = {a^{n}b^{n}c^{p} | n \geq{} 0} is not at CFL.

u | v | x | y | z
aaaaa|bbbbb|ccccc

Assume B is a CFL and let p be the pumping length for B. Choose s = a^{p}b^{p}c^{p} \in B so that clearly s > p. By condition 1 of the PL for CFLs, we can partition s = uvxyz such that for all i \geq{} 0, uv^{i}xy^{i}z \in B. In order to show that s cannot be pumped, let's consider the ramifications of Condition 2 of the PL for CFLs for the contents of v and y

When both v and y contain only one type of symbol (terminal). V does not contain both a's and b's or both b's and c's and the same holds for y. Then s' = uv^{2}xy^{2}z cannot contain equal numbers of a's b's and c's. Therefor s' \notin{} B and condition 1 of the PL for CFLs is violated.

When either v or y contain more than one type of symbol (terminal). S' uv^{2}xy^{2}z may contain equal numbers of these symbols but the symbols are in the wrong order. Hence s' \notin B, becasue condition 1 of PL(CFLs) is violated since one of the above cases must apply for any s \in B, we can conclude that B is not a CFL.#

** Example
C = {a^{i}b^{j}c^{k} | 0 \leq i \leq j \leq k} is not a CFL.

Choose s = a^{p}b^{p}c^{p} \in C so that clearly s > p. By condition 1 of the PL for CFLs, we can partition s = uvxyz such that for all i \geq 0, uv^{i}xy^{i}z.

*** Case The a's do not appear
In htis case either the a's and c's cannot appear in V & y:w

because both cannot be the empty string due to cond 2
If a's appear in S' = uv^{2}xy^{2}z, the s' has more a's than b's and so S' \notin C. Similarily if c's appear in s' = uv'{0}xy^{y}z

* Turing Machines

- similar to a FA with a supply of unlimited memory, can do everything a modern computing device can do
- Memory is modeled by a tape of symbols
- Initially tape contains only the input string and blanks everywhere else
- A TM can store informatio nby writing symbols on the tape
- The tae can move its head left and right to read symbols
- TM continues to move until it enters a state in which the next move is not defined

** TM -vs- FA, PDA
Write
- A TM tape allows both write and read ops, DFA and NFA only have an input tape, and the tape moves form left to right. A PDA has both an input tape and statck tape, we can read/write on the stack tape, right = write, left = erase
Size
- The TM tape is infinite; the input of FA/PDA is finite, the stck of a PDA is infinite
Accept
- Fa/PDA accept a string when it has scanned all the input symbols and enters a final state, a TM accepts a string as long as it enters a final state (one suffices)

** Example
Construct a TM M_{1} that tests the membership of the language L_{1} = {w#w | w \in {0,1}^{*}}. In other works design a M_{1} such that M_{1}(w) = accept \iff w \in L_{1}. Position of the tape head is underlined
 | S_{0},a = 0 | _0_10#010 |
 | s_{1}       | x10_#_010 |
 | s_{2}       | x10#_x_10 |
 | s_{3}       | x10_#_x10 |
 | s_{4}       | _x_10#x10 |
 | s_{0},a = 1 | x_x_0#x10 |

*** Definition for Above
| S_{0}    | If symbol read is a 0 or 1, replace with x and remember the symbol as a               |
|          | if the symbol is a # go to S_{5}, else reject                                         |
|          | \delta{}(S_{0},0}) = (S_{1}(0),x,R), \delta{}(S_{0},1) = (S_{1}(1),x,R)               |
|          | \delta{}(S_{0},#) = (S_{5},#,R)                                                       |
| S_{1}(a) | Move right until a # is found, if not # is found before blank, reject                 |
| S_{2}(a) | Move right until a 0 or 1 is found; if current symbol == a, replace by x, else reject |
| S_{3}    | Move right until a # is found                                                         |
| S_{4}    | Move right until a x is found and go to S_{0}                                         |
| S_{5}    | Move right until a 0, 1, or blank is found; accept if current symbol is blank         |
|          | Reject if current symbol is a 0 or 1                                                  |

** Formal Definition
1. Q is a set of states
2. \Sigma is the input alphabet and a blank \notin \Sigma
3. \Gamma{} is the tap ealphabet, blank \in \Gamma, \Sigma{} \subset \Gamma
4. \delta{}: Q \times{} \Gamma{} \rightarrow{} Q \times{} \Gamma{} \times{} {L, R} is the transition function
5. q_{0} \in Q is the start state
6. q_{accept} is the accept state (q_{a}), and q_{reject} is the reject state q_{r}

** How does it compute?
- M receives as input w=a_{1}a_{2},...a_{n} \in \Sigma^{*} written on the leftmost squares of the tape (rest of tape contains blanks)
- The head starts on the leftmost square of the tape and the first blank encountered signals the end of input
- Once M starts it proceeds according to \delta{}, M stays on the leftmost square (of input) even if \delta{} indicates a left move (L) from that square
- Computation continues until M cannot move; w is accepts if M enters q_{accept}

** Formalizing TM Computation
- A configuration C of the TM is a 3-tuple C = <u,q,v>, where q \in Q, u,v \in \Gamma{}^{*} is the tape content and the head is pointing to the first symbol of v
- A configuation C_{1} yields a configuation C_{2} if the TM can (legally) go from C_{1} to C_{2} in a single computation (step). Suppose a,b,c \in \Sigma{}; u,v \in \Gamma{}^{*} and q_i, q_j \in Q

* Add 1 to a binary number
0b111 => 0b1000
0b1 => 0b10
0b1010 => 0b1011

[[file:add1_tm.png]]

* Compare unary numbers 11#111
[[file:compare_unary.png]]

* Exam 2 Prep
1. TM
   - not a context free language
2. T
   -
3. eS1, eeA, ee0 (read, pop, push)
   -
4. F
   - turing recognizable, can loop or reject
5. s
   - q0xA, read a 0 move to state s, read an A move to the right
   - AsxA
   - q0xA
     - q = state
     - 0xA = tape
   - Therefore the new configuration after the rule \delta(q,0) = <s,A,R> is
     - AsxA
6. t
   - 1t0x <new state, write, move>
   - \delta(q,x) = <t,x,L>
   - 10qx
   - 1t0x
7. 4
   - No unit rules,
8. 1
   -
9. F
10. Not in the language, reject
11. S -> Aa | a | ABA | BA | AB | B
12. No changes to s
    - Change occurs to A, A -> b|a

* Decidability
Decidable \iff there is a TM that can be built that will decide (halt) on all inputs

** Membership for DFA
Test whether a particular FA accepts a given string (denoted by A_{DFA}). A_{DFA} contains encodings of all DFA's together with the strings that the DFA's accept
- A_{DFA} = {<B,w> | B is a DFA that accepts w}

Testing whether DFA B accepts w is the same as testing whether <B,w> \in A_{DFA}. To show that computational problem is decidable is to show that the encoding of the problem is decidable

*** Theorem
A_{DFA} is a decidable language

Proof
- Construct a TM M that decides A_{DFA}
- M = "On input <B,w>, where B is a DFA and w is a string"
  - Simulate B on w
  - In simulation ends in accepts state, M accepts; if simulation ends in a non-accept state, M rejects. Note: w is finite and the simulation always ends

** Acceptance for NFA
Convert NFA to DFA then use above

** Emptiness Problem
Test if the language of a DFA is empty
- E_{DFA} = {<A> | A is a DFA and L(A) = 0}

*** Theorem
E_{DFA} is a decidable language

Proof
- DFA A accepts some string \iff it reaches a final state from the start state and travelling along the edges of the DFA. Construct a TM say T that marks the states of the DFA A using the \delta function of A. We then use T to solve the emptiness problem.

- Run and run then ensure that no final state was ever marked

** Language Equality
Are 2 DFAs equal?
- Every string accepted by A is also accepted by B
- Recall that the symmetric difference L(C) = [L(a) \intersection{} \bar{L(B)}] \union{} [\bar{L(A)} \intersection{} L(B)] defines what is unique to each of the languages L(A) and L(B). If L(C) = \empty{}, then L(A) = L(B).

- construct DFA C that recognizes L(C), the symmetric difference of L(A) and L(B)
- Run TM from previous example
- If T accepts, then F accepts; otherwise F rejects

** Given any DFA A on \Sigma{}, can we decide if L(A) = \Sigma{}^{*}
We can build a DFA for the complement of a language
Then run the above emptiness problem on it again

** Can we describe algorithms to test whether a CFG generates a particular string
A_{CFG} = {<G,w> | G is a CFG that generates the string w}

*** Theorem
- Go through all derivations generates by G checking wheter one of them is a derivation of w. But there are infinitely-many derivations?

- If G does not generate w, the algorithm does not halt; so we could only produce a recognizer not a deicder
- How can we redesign the recognizer into a decider and only process a finite number of derivations?
  - If G is a CFG in CNF the nfor any w \in L(G), where |w| = n, exactly 2n-1 steps are required for any derivation of w
- A_{CFG} is a decidable language
- Construct the TM S that decides A_{CFG}. S="On input <G,w>, where G is a CFG and w is a string
  - Convert G to an equivalent grammar in CNF
  - List all derivations using 2n-1 steps, where n = len(w); if n = 0, list all derivations in 1 step
  - If any derivations produce w, S accepts; otherwise S rejects

** Emptiness Problem for CFGs
E_{CFG} = {<G> | G is a CFG and L(G) = 0}

*** Theorem
E_{CFG} is a decidable language

- To test whether L(G) is empty, we need to test whether the G can generate a string of termainals. Moreover, can each variable generate a string of terminals
- We need to have an algorithm to cross off terminals and the variables whose grammar rules have right hand sides comprised of those terminals

- Proof

*Every CFL is decidable*

** Lemma: Class of CF languages is *NOT* closed under *\intersect{}$
$A = \{a^{m}b^{n}c^{n} | m,n \geq{} 0\}$
$B = \{a^{n}b^{n}c^{m}|m,n\geq{}0\}$
$C = \{a^{n}b^{n}c^{n} | n \geq{} 0\}$ not a cfl

$S \rightarrow{} RT, R \rightarrow{} aR | \epsilon{}, T \rightarrow{} bTc | \epsilon{}$
$S \rightarrow{} TR, T \rightarrow{} aTb|\epsilon{}, R \rightarrow{} cR|\epislon{}$

** Lemma: Class of CF lanuages is *NOT* closed under complementation
Assume class of CFLs is closed under complementation

If G_{1} and G_{2} are CFG's, then \bar{L(G_{1})} and \bar{L(G_{2})} are CFLs

DeMorgan's Law: \bar{L(G_{1})} \union{} \bar{L(G_{2})} = L(G_{1}) \intersect{} L(G_{2}) but that language is not CFL by the previous lemma

** CFL Equality Problem
EQ_{CFG} = {<G,H> | G,H are CFGs and L(G) = L(H)}

Can't une symmetric difference now since CFLs are NOT closed under intersection and complementation

*** Theorem
EQ_{CFG} is not a decidable language

Proof by contradiction
- Construct a CFG H such that L(H) = \Sigma{}^{*}
- Run the decider for EQ_{CFG} on <G,H>
- If the decider accepts, then M accepts; otherwise M rejects

So, M decides ALL_{CFG} assuming a decider for EQ_{CFG} exists. But ALL_{CFG} can be shown to be undecidable. This is a reducibility argument that we will revisit later

** Overall Methodology (for proving the a language is decidable)
- Understand relationship between languages
- Transform relationship into an expression using closure operators on decidable languages
- Design a TM that constructs language expressed
- Run TM that decides the language

* Halting Problem
Membership problem, does a TM accept a given input string?
- A_{TM} = {<M,w> | M is a TM and M accepts w}

The language A_{TM} is *not* decidable but A_{TM} is Turing-recognizable
Let's construct a recognizer for A_{TM}
U = "On input <M, w>, where M is a TM and w is a string"

1. Simulate M on the input w
2. If M ever enters its accept state, U accepts; if M ever enters its reject state, U rejets
   1. U loops on the input <M, w> if M loops on w and this is why U does not decide A_{TM}

If the algorithm has some way to determine that M was not halting on w, it could reject, this is known as the halting problem

The TM U (named for "universal TM") was proposed by Alan Turing and played an important role in the development of future stored-program copmuters

** Undecidability
How can we prove a language is undecidable?

For TM membership, we can explpoit George Cantor's diagonalization technique (1873); he wanted to measure the size of infinite sets (i.e., count the number of elements in the set)

However such a counting approach would not halt

*** Infite Sets
- Set of strings over {0,1}
- N, set of natural numbers
- E, set of all even natural numbers

Cantor's solution for comparing infinite sets; two infinite sets have the same size if their elements can be paired

Two sets A and B have the same size if there is a correspondence f: A \rightarrow{} B.
We say f is 1-to-1 if it never maps two different elements of A into hte same elements of B, i.e., f(a) \neq{} f(b) whenever a \neq{} b.
We say f is onto if it hits every elements of B, i.e., for all b \in B, there exists a \in A such that f(a) = b.
We conclude that f is a correspondence if it is both 1-to-1 and onto

*** Rational Numbers are Countable
1. Consider the cross produce of N \times{} N on a cartisian graph (2D Array)
2. Row i contains the following $\{i / j \in Q | i \in N, \forall{} j \in N \}$
3. Col j contains the following $\{i/j \in Q | j \in N, \forall{} i \in N\}$
4. Number i/j occurs i nthe i'th row and j'th column

These are countable (infinite) sets: N\times{}N, N^{k} for any k, \Sigma{}^{*} and any subset of a countable set

Example of an uncountable set: R-the set of real numbers

** Proving that the real numbers are uncountable
Proof: suppose a corespondence f: N \rightarrow{} R exists and deduce a contradiction that f cannot be a correspondence, i.e., construct x \in R that cannot be the image of any n \in N. Assuming the correspondence f exists, we can list all real numbers. Now, construct x \in (0,1) as follows

1. Let x = 0.d_{1}d_{2}d_{3}d_{4}... with an infinite number of decimals constructed by the following rule: for all i \in N choose d_{i} to be different from ith digit of f(i)
2. Then, for all i \in N, x \neq{} f(i). So x does not belong to our list of all real numbers and f is not a correspondence (contradiction).

Some languages are not decidable or event Turing-recognizable

There are countable many TMs but an uncountable number of languages; each TM can recognize a single language and there are many more languages than TMs so what can we conclude?

That there will be languages that are *NOT* recognized by a TM (these are not T-recognizable)

Set of all formal languages L = \{L|L \subset{} \Sigma^{*}\} is uncountable

** Can we construct a Turing-unrecognizable language?
Recall that A_{TM} is a Turing undecidable language but it is Turing-recognizable(TR). Construcitng a TR languages relies on the fact that if both a language and its complement are TR, then the langugage is decidable. Hence, for any undecidable language, either the language or its ocmplement is not TR

*** Theorem
$A_{TM} = \{<M,w> | \text{M is a TM and M accepts w}\}$ is undecidable

*** Proof
Assume A_{TM} is decidable and suppose H is a decider of A_{TM}. On input <M,w>, where M is a TM and w is a string, H halts and accepts if M accepts w. SImilarly, H halts and rejects if M fails to accept w.

Now construct a new TM D that uses H as a subroutine. That is, D calls H to determine what M does when its input is w = <M>.

So if M accepts <M>, then D(<M>) rejects and if M rejects <M> then D(<M>) accepts (opposite of what H outputs). Now run D on <D>, then D(<D>) returns accepts if D doesn't accept <D> and D(<D>) returns reject if D doesn't reject <D>. The problem is that this will never finish executing

|       | <M_{1}> | <M_{2}> | <M_{3}> | <M_{4}> |
| M_{1} | accept  |         | accept  |         |
| M_{2} | accept  | accept  | accept  | accept  |
| M_{3} |         |         |         |         |
| M_{4} | accept  | accept  |         |         |

Now run H..
|       | <M_{1}> | <M_{2}> | <M_{3}> | <M_{4}> |
| M_{1} | accept  | reject  | accept  | reject  |
| M_{2} | accept  | accept  | accept  | accept  |
| M_{3} | reject  | reject  | reject  | reject  |
| M_{4} | accept  | accept  | reject  | reject  |

Now create D
Now run H..
|       | <M_{1}> | <M_{2}> | <M_{3}> | <M_{4}> | <D>    |
| M_{1} | accept  | reject  | accept  | reject  | accept |
| M_{2} | accept  | accept  | accept  | accept  | accept |
| M_{3} | reject  | reject  | reject  | reject  | reject |
| M_{4} | accept  | accept  | reject  | reject  | accept |
| D     | reject  | reject  | accept  | accept  | ?      |

D returns the opposite of <M_{i} <M_{i}>>

[[file:venn.png]]

* Reducibility
- Reduction is a terminating process
- When A is reduced to B, solving problem a cannot be harder than the sum of reduction and solving B. Solution to B should solve A
- A is reduced to B that is decidable, than A is decidable
- A is undecidable and is reducible to B, then B is undecidable

** Example
A reduces to B (measuring R, the radius)

** Strategy
1. Find a problem Q known to be undecidable
2. Assume P is decidable by a TM M_{p}
3. Use TM M_{p} to construct a TM M_{Q} that solves Q: encode every instance q of problem Q as an instance q_{p} of problem P. Use M_{p} to solve q_{p}

Since it is known that Q is undecidable, M_{Q} cannot exist so M_{p} cannot exist and P is undecidable.

$A_{TM} = \{<M,w> | \text{M is a TM and M accepts w\}$

HALT_{TM} is undecidable

** Does a TM have an equivalent automaton
$REGULAR_{TM} = \{<M> | \text{M is a TM and L(M) is regular}\}$

The above is undecidable

* Decidability Proofs
Prove that L_{X} = $\{<M> | \text{M is a TM that writes an x on some cell of the tape when started on a blank}\}$ is undecidable

** Proof
Assume L_{X} is decidable and let R be a TM that decides it.
S = "On input <M,w>, where M is a TM and w is an input string do:"
1. Construct a new TM M_{w} such that on an input y, we substitue X for x everywhere in <M> and w yieling <M',w'>
2. Run M' on the input w' so that if M' rejects, then M_{w} wil lreject also'; similarly, if M' accepts w' then print x on the tape and have M_{w} accept
3. Now, run R on <M_{w}> so that if R accepts, then S will accpet and similarly, if R rejects then S will reject

If M accepts w then M_{w} will print x on any input (including a blank) and if M rejects w or loops on w (i.e., does not halt) then M_{w} is guaranteed to never print an x on the tape. Therefore, the TM S decides A_{TM} since for any input w and TM M would halt and either accept or reject w. Hence L_{X} has been reduced to A_{TM} and we already know that A_{TM} is undecidable. We can conclude that L_{x} must also be undecidable


* 3x+1
function, 3x+1 for odd x, x/2 for even x

If you start with an integer x and iterate f, you obtain a sequence $x, f(x), f(f(x))

and stop if you ever hit 1. for example if x = 17, you would get the sequence

Extensive computations have shown that every starting point between 1 and a large positive integer yields a sequence that ends in 1. But, the question of whether all positive starting integers yields a sequence terminating at 1 is unsolved

** Why
On input <n>, where n is a natural number, run the 3x+1 procedure starting at n and accept if and when a 1 is reached. If one is never reached then S will not halt

Now define another TM T with input <n> that uses TM H to determine whethere or not S accepts <n>. If S accepts then T will accept and if S does not accept, T will halt and reject.

Define the TM P on any input htat runs the TM T on inputs 1,2,3,... and accept if T is found to reject any of hte inputs; otherwise P will not halt

Finally define the TM Q on any input that uses TM H to determine whethere or not the TM P accepts <0> and outputs "conjecture is false" if P accepts <0>, and outputs "conjecture is true" if P does not accept <0>. jthis TM Q would therefore answer the 3x+1 problem and decide A_{TM}

* Complexity
In analyzing TM_{A}, the time to decide the language A depends on the number of steps that TM_{A} moves -- normally depends on several parameters.
1. The running time of an algo is a function of the length of the string that represents the input
2. Worst-case-analysis is the longest running time of all inputs of the same length
3. Average-case-analysis is the average of all running itmes of inputs of the same lenth

** Example
Let M be a deterministic TM that halts on all inputs. The running time or time complexity of M is a function f: N \rightarrow{} N, where f(n) is the maxiumum number of steps that M uses on any input of length n.

If f(n) is the running time of M we say that M runs in time f(n) and that M is a f(n) time TM, where n is the length of the input

Usually we estimate running time of an algorithm (exact time may be too complicated to determine)

** Asymptotic Analysis
determine running time of algo on large inputs; consider only the highest order term of running time expression (dominates values of other terms on large inputs)
- $f(n) = 6n^{3}+2n^{2}+10n+100$
- We say that f is asymptotically at most n^{3}, and write f(n) = O(n^{3})

Let f and g be functions, f,g: N \rightarrow{} R. We say that f(n) = O(g(n)), if positive integers c and n_{0} exist such that for all n \geq{} n_{0}, f(n) \leq{} cg(n). We say tht g(n) is an asymptotic upper bound for f(n) with the suppression of constant factors

In practice most functions f will have an obvious highest order term h(n) so that
