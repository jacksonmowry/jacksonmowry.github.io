#+title: Microservices Hate
* Decoupling and Testing
Let's say we have service A which is our major service which supports most of the user facing product. The service doesn't house anything related to customer accounts or authentication (Service B). Because you are practicing good test driven development every new feature added to service B is supported with a vast swath of tests. You cover every case you can think of, and especially the major business requirements the motivated this development in the first place. All is well and good, so you get your changed up for review.

Your teams signs off the on the changes as your tests perfectly match the requirements outlined in the ticket. Service B is the pushed out into the CI/CD pipeline, and here comes the problem. Service A is highly dependent on service B, as each and every request to service A requires authorizaiton checks. Another developer is working locally on service A and starts to notice test failures that seem entirely unrelated to what they are working on, so they decide to scrap their changes and try to run the tests with the changes as they are in version control. Still no luck though, the same tests are failing, which is reassuring for the single developer and their changes, but terrible for the users.

So now the developer begins to investigate the failure, a majority of the errors are =403=, so maybe something happened with user permissions? The developer checks recent changes to service B and notices the changes that are making their way through the CI/CD pipeline, but of course the tests are all passing so they look elsewhere. At the end of the day authorization all comes back to user account management which is managed by another team, so they leave a message in their communications channel to see if any other teams are experiencing the same issue. At the same time this developer begins to message their immediate team to see if the issue is reproducable.

A short while later everyone on the team is able to reproduce the issue and the attitude quickly shifts. The recent changes to service B are on their way out to production, so that pipeline is quickly paused. The team chooses a single end point to troubleshoot and  starts to hammer it with different requests. They quickly realize the issue is related to a specific category of user which even further narrows down the problem, and before long someones takes a look at the database and realizes the change to service B entirely broke access for this user type.

It's a good thing that developer was working on service A early enough to stop the changes to service B from making it to production, but that shouldn't have been what caught the buggy changes. The changes should have been tested in the real world with all of the possible services before making it past the development environment. In a microservice based architecture of course you could just run every single service's test suite against anothers, but that matrix of possibilities quickly explodes as the number of microservices grows, and it should grow if you're "doing it right".

What could have prevented this? A simple monolith. With every service owning its own database, a seemingly harmless change to one service can break any number of the other services that depends on it, and as stated before that can't be tested until the service is deployed to at least a development or staging environment. If the application were to instead be a monolith, every test would be run everytime, preventing the risk of one service breaking another. Every developer could be confident that their changes are going to work just as well in the cloud as they did on their local machine.

* How in the hell are you supposed to test event driven applications
The entire purpose of the application is so that messages can be processed asynchronously with no strict ordering. We also don't have time garuntees on these message processors. In one example a processor has 7 days to respond, so is my test supposed to wait 7 days to complete?

In a smaller example I publish a change message indicating that a user updated their address, which needs to be acknowledged by a billing/shipping service. I write a test that publishes that message, and immedietely check the billing/shipping service for the information to be reflected, but that didn't give enough time for that service to process the message. What am I to do? Add a 10 second sleep? That's incredibly stupid. I guess I could have the billing/shipping service send me a message once it's done. Ok, that works great in test, but I want to test against the production service, and there's no good reason to add code to a production service just to support testing. So my options are then to emulate my messaging queue which entirely defeats the purpose of integration testing a service.
